# ğŸ” Swiggy Delivery Time Prediction

A machine learning project that predicts food delivery times using a complete MLOps pipeline with DVC, MLflow, and FastAPI. This project demonstrates end-to-end ML workflow from data cleaning to model serving.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Project Pipeline](#project-pipeline)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [API Documentation](#api-documentation)
- [Model Performance](#model-performance)

## ğŸ¯ Overview

This project predicts the delivery time for food orders placed on Swiggy (Indian food delivery platform) based on features like:
- Delivery person details (age, ratings, experience)
- Restaurant and delivery location coordinates
- Weather conditions and traffic density
- Order type and vehicle type
- Time of day and festival information

**Key Technologies:**
- **Data Pipeline:** DVC (Data Version Control)
- **ML Workflow:** Scikit-learn, LightGBM, Random Forest
- **Model Tracking:** MLflow + DagsHub
- **API Server:** FastAPI + Uvicorn
- **Model Serialization:** Joblib

---

## ğŸ“Š Project Pipeline

The project follows a modular DVC pipeline with the following stages:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Data       â”‚
â”‚  (swiggy.csv)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: Data Cleaning      â”‚
â”‚ - Handle missing values     â”‚
â”‚ - Remove outliers           â”‚
â”‚ - Feature engineering       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 2: Data Preparation    â”‚
â”‚ - Train/Test split (75/25)   â”‚
â”‚ - Save split datasets        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 3: Data Preprocessing          â”‚
â”‚ - Numerical: MinMaxScaler            â”‚
â”‚ - Categorical: OneHotEncoder         â”‚
â”‚ - Ordinal: OrdinalEncoder            â”‚
â”‚ - Save preprocessor artifact         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 4: Model Training              â”‚
â”‚ - Random Forest Regressor            â”‚
â”‚ - LightGBM Regressor                 â”‚
â”‚ - Stacking Ensemble                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 5: Model Evaluation            â”‚
â”‚ - Calculate MAE, RÂ² scores           â”‚
â”‚ - Cross-validation                   â”‚
â”‚ - Log metrics to MLflow              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Run the entire pipeline:**
```bash
dvc repro
```

---

## ğŸ“ Project Structure

```
swiggy-delivery-time-prediction/
â”‚
â”œâ”€â”€ app.py                          # FastAPI application for model serving
â”œâ”€â”€ Dockerfile                       # Docker configuration for containerization
â”œâ”€â”€ requirements.txt                 # Core dependencies
â”œâ”€â”€ requirements-dev.txt             # Development dependencies
â”œâ”€â”€ requirements-dockers.txt         # Docker-specific dependencies
â”œâ”€â”€ .env.example                     # Environment variables template
â”œâ”€â”€ .gitignore                       # Git ignore rules
â”œâ”€â”€ .gitattributes                   # Git LFS configuration
â”œâ”€â”€ dvc.yaml                         # DVC pipeline definition
â”œâ”€â”€ dvc.lock                         # DVC lock file (tracked in Git)
â”œâ”€â”€ params.yaml                      # Hyperparameter configuration
â”œâ”€â”€ README.md                        # This file
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # Original dataset
â”‚   â”‚   â””â”€â”€ swiggy.csv
â”‚   â”œâ”€â”€ cleaned/                     # Cleaned data
â”‚   â”‚   â””â”€â”€ swiggy_cleaned.csv
â”‚   â”œâ”€â”€ interim/                     # Train/test split
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â””â”€â”€ test.csv
â”‚   â””â”€â”€ processed/                   # Preprocessed data
â”‚       â”œâ”€â”€ train_trans.csv
â”‚       â””â”€â”€ test_trans.csv
â”‚
â”œâ”€â”€ models/                          # Trained model artifacts
â”‚   â”œâ”€â”€ model.joblib                 # Stacking ensemble model
â”‚   â”œâ”€â”€ preprocessor.joblib          # ColumnTransformer for preprocessing
â”‚   â”œâ”€â”€ power_transformer.joblib     # Power transformer artifact
â”‚   â””â”€â”€ stacking_regressor.joblib    # Stacking regressor component
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_cleaning.py         # Data cleaning stage
â”‚   â”‚   â”œâ”€â”€ data_preparation.py      # Train/test split stage
â”‚   â”‚   â””â”€â”€ data_preprocessing.py    # Feature preprocessing stage
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_preprocessing.py    # Feature engineering (wrapper)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train.py                 # Model training stage
â”‚   â”‚   â”œâ”€â”€ evaluation.py            # Model evaluation stage
â”‚   â”‚   â””â”€â”€ register_model.py        # Model registration (optional)
â”‚   â””â”€â”€ visualization/
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_clean_utils.py          # Data cleaning utilities
â”‚   â”œâ”€â”€ sample_predictions.py        # Example prediction script
â”‚   â””â”€â”€ promote_model_to_prod.py     # Model promotion script (optional)
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_model_registry.py       # Model registry tests
â”‚   â””â”€â”€ test_model_perf.py           # Model performance tests
â”‚
â”œâ”€â”€ notebooks/                       # Jupyter notebooks for exploration
â”‚   â””â”€â”€ (exploratory analysis)
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/                     # Generated figures and reports
â”‚
â”œâ”€â”€ docs/                            # Documentation
â”‚   â”œâ”€â”€ commands.rst
â”‚   â”œâ”€â”€ getting-started.rst
â”‚   â””â”€â”€ index.rst
â”‚
â””â”€â”€ references/                      # Reference materials
```

---

## ğŸ”§ Installation

### Prerequisites

- Python 3.11+
- pip or conda
- Docker (optional, for containerization)
- Git and Git LFS

### Step 1: Clone the Repository

```bash
git clone https://github.com/AmitZala/swiggy-delivery-time-prediction.git
cd swiggy-delivery-time-prediction
```

### Step 2: Create Virtual Environment

**Using venv:**
```bash
python -m venv venv
.\venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac
```

**Using conda:**
```bash
conda create -n swiggy-delivery python=3.11
conda activate swiggy-delivery
```

### Step 3: Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
pip install -r requirements-dev.txt
pip install python-dotenv
```

### Step 4: Install DVC and Git LFS

```bash
pip install dvc
git lfs install
```

### Step 5: Pull DVC Data (Optional)

```bash
dvc pull
```

---

## âš™ï¸ Configuration

### Environment Variables

1. Copy `.env.example` to `.env`:
```bash
cp .env.example .env
```

2. Edit `.env` with your actual credentials:
```env
# DagsHub Configuration
DAGSHUB_REPO_OWNER=YourUsername
DAGSHUB_REPO_NAME=your-repo-name

# MLflow Configuration
MLFLOW_TRACKING_URI=https://dagshub.com/YourUsername/your-repo-name.mlflow
MLFLOW_EXPERIMENT_NAME=DVC Pipeline

# FastAPI Configuration
FASTAPI_HOST=127.0.0.1
FASTAPI_PORT=8000

# Model and Data Paths
MODEL_PATH=models/model.joblib
PREPROCESSOR_PATH=models/preprocessor.joblib

# Other configurations
USE_MLFLOW_REGISTRY=false
TARGET_COLUMN=time_taken
```

### DVC Remote Configuration (Optional)

```bash
dvc remote add -d dagshub "https://dagshub.com/YourUsername/your-repo-name.dvc"
dvc remote modify dagshub --local auth basic
dvc remote modify dagshub --local user YourUsername
dvc remote modify dagshub --local password "YOUR_DAGSHUB_TOKEN"
```

---

## ğŸš€ Usage

### 1. Run the Complete Pipeline

```bash
cd d:\swiggy-delivery-time-prediction
dvc repro
```

This will execute all stages:
- Data cleaning
- Data preparation (train/test split)
- Data preprocessing (feature transformation)
- Model training
- Model evaluation

### 2. Start the FastAPI Server

```bash
python app.py
```

The API will be available at: `http://127.0.0.1:8000`

### 3. Access Interactive API Documentation

Open your browser and go to:
- **Swagger UI:** `http://127.0.0.1:8000/docs`
- **ReDoc:** `http://127.0.0.1:8000/redoc`

### 4. Make Predictions via API

**Using Python requests:**
```python
import requests

payload = {
    "ID": "1",
    "Delivery_person_ID": "DP_001",
    "Delivery_person_Age": "28",
    "Delivery_person_Ratings": "4.5",
    "Restaurant_latitude": 12.9716,
    "Restaurant_longitude": 77.5946,
    "Delivery_location_latitude": 12.9352,
    "Delivery_location_longitude": 77.6245,
    "Order_Date": "2022-01-01",
    "Time_Orderd": "12:00",
    "Time_Order_picked": "12:10",
    "Weatherconditions": "Sunny",
    "Road_traffic_density": "Medium",
    "Vehicle_condition": 5,
    "Type_of_order": "Food",
    "Type_of_vehicle": "Bike",
    "multiple_deliveries": "1",
    "Festival": "No",
    "City": "Bengaluru"
}

response = requests.post("http://127.0.0.1:8000/predict", json=payload)
print(f"Predicted delivery time: {response.json()} minutes")
```

**Using curl:**
```bash
curl -X POST "http://127.0.0.1:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "ID":"1",
    "Delivery_person_ID":"DP_001",
    "Delivery_person_Age":"28",
    "Delivery_person_Ratings":"4.5",
    "Restaurant_latitude":12.9716,
    "Restaurant_longitude":77.5946,
    "Delivery_location_latitude":12.9352,
    "Delivery_location_longitude":77.6245,
    "Order_Date":"2022-01-01",
    "Time_Orderd":"12:00",
    "Time_Order_picked":"12:10",
    "Weatherconditions":"Sunny",
    "Road_traffic_density":"Medium",
    "Vehicle_condition":5,
    "Type_of_order":"Food",
    "Type_of_vehicle":"Bike",
    "multiple_deliveries":"1",
    "Festival":"No",
    "City":"Bengaluru"
  }'
```

### 5. Run Sample Predictions

```bash
python scripts/sample_predictions.py
```

---

## ğŸ³ Docker Usage

### Build Docker Image

```bash
docker build -t amitzala93/swiggy-delivery-time-prediction:latest .
```

### Run Container Locally

```bash
docker run -p 8000:8000 amitzala93/swiggy-delivery-time-prediction:latest
```

### Push to Docker Hub

```bash
docker login
docker push amitzala93/swiggy-delivery-time-prediction:latest
```

---

## ğŸ“¡ API Documentation

### Endpoints

#### 1. **Home Endpoint**
- **Route:** `GET /`
- **Description:** Welcome message
- **Response:** `"Welcome to the Swiggy Food Delivery Time Prediction App"`

#### 2. **Predict Endpoint**
- **Route:** `POST /predict`
- **Description:** Make delivery time predictions
- **Input:** JSON with delivery details (see Usage section)
- **Output:** Predicted delivery time in minutes (float)

#### 3. **API Documentation**
- **Swagger UI:** `GET /docs`
- **ReDoc:** `GET /redoc`
- **OpenAPI Schema:** `GET /openapi.json`

---

## ğŸ“ˆ Model Performance

The trained ensemble model combines:
- **Random Forest Regressor** (479 estimators, max_depth=17)
- **LightGBM Regressor** (154 estimators, max_depth=27)

**Hyperparameters are defined in `params.yaml`**

### Evaluation Metrics

Metrics are logged to MLflow and include:
- **Mean Absolute Error (MAE)** - Training & Testing
- **RÂ² Score** - Training & Testing
- **Cross-Validation Scores** (5-fold CV)

---

## ğŸ”„ DVC Pipeline Stages

### Stage 1: data_cleaning
```bash
cmd: python src/data/data_cleaning.py
deps:
  - data/raw/swiggy.csv
  - src/data/data_cleaning.py
outs:
  - data/cleaned/swiggy_cleaned.csv
```

### Stage 2: data_preparation
```bash
cmd: python src/data/data_preparation.py
params:
  - Data_Preparation.test_size
  - Data_Preparation.random_state
deps:
  - data/cleaned/swiggy_cleaned.csv
  - src/data/data_preparation.py
outs:
  - data/interim/train.csv
  - data/interim/test.csv
```

### Stage 3: data_preprocessing
```bash
cmd: python src/features/data_preprocessing.py
deps:
  - data/interim/train.csv
  - data/interim/test.csv
  - src/features/data_preprocessing.py
outs:
  - data/processed/train_trans.csv
  - data/processed/test_trans.csv
  - models/preprocessor.joblib
```

### Stage 4: train
```bash
cmd: python src/models/train.py
params:
  - Train.Random_Forest
  - Train.LightGBM
deps:
  - src/models/train.py
  - data/processed/train_trans.csv
outs:
  - models/model.joblib
  - models/power_transformer.joblib
  - models/stacking_regressor.joblib
```

### Stage 5: evaluation
```bash
cmd: python src/models/evaluation.py
deps:
  - src/models/evaluation.py
  - data/processed/train_trans.csv
  - data/processed/test_trans.csv
  - models/model.joblib
outs:
  - run_information.json
```

---

## ğŸ› ï¸ Development

### Run Tests

```bash
pytest tests/ -v
```

### Check Code Quality

```bash
pylint src/ --disable=all --enable=E
```

### View DVC Status

```bash
dvc status -c
dvc dag
```

### Push DVC Cache

```bash
dvc push
```

---

## ğŸ“ Environment Variables Reference

| Variable | Example | Purpose |
|----------|---------|---------|
| `DAGSHUB_REPO_OWNER` | `AmitZala` | DagsHub repository owner |
| `DAGSHUB_REPO_NAME` | `swiggy-delivery-time-prediction` | DagsHub repository name |
| `MLFLOW_TRACKING_URI` | `https://dagshub.com/...mlflow` | MLflow server URI |
| `MLFLOW_EXPERIMENT_NAME` | `DVC Pipeline` | MLflow experiment name |
| `FASTAPI_HOST` | `127.0.0.1` | FastAPI server host |
| `FASTAPI_PORT` | `8000` | FastAPI server port |
| `MODEL_PATH` | `models/model.joblib` | Path to trained model |
| `USE_MLFLOW_REGISTRY` | `false` | Enable MLflow model registry |

---

## ğŸ› Troubleshooting

### Issue: `dvc pull` fails with missing cache files
**Solution:** Ensure DVC remote is configured and has sufficient permissions.

### Issue: `pylint: command not found` in CI
**Solution:** Install pylint: `pip install pylint`

### Issue: FastAPI app won't start
**Solution:** Check if port 8000 is already in use or verify `.env` configuration.

### Issue: Model not loading from MLflow registry
**Solution:** Set `USE_MLFLOW_REGISTRY=false` in `.env` to load from local storage.

---

## ğŸ“š Resources

- [DVC Documentation](https://dvc.org/doc)
- [MLflow Documentation](https://mlflow.org/docs)
- [FastAPI Documentation](https://fastapi.tiangolo.com)
- [Scikit-learn Documentation](https://scikit-learn.org)
- [LightGBM Documentation](https://lightgbm.readthedocs.io)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ‘¤ Author

**Amit Zala**
- GitHub: [@AmitZala](https://github.com/AmitZala)
- Project: [swiggy-delivery-time-prediction](https://github.com/AmitZala/swiggy-delivery-time-prediction)

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“§ Contact

For questions or suggestions, please open an issue on GitHub or contact the maintainer.

---

**Last Updated:** December 2025
